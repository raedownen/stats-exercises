{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bdf85f17",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47ae17d5",
   "metadata": {},
   "source": [
    "How to make a distribution (or simulate it) and use the distribution methods on them?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c0a0b0",
   "metadata": {},
   "source": [
    "n_trials = nrows = 10_000\n",
    "n_dice = ncols = 3\n",
    "\n",
    "rolls = np.random.choice([1, 2, 3, 4, 5, 6], n_trials * n_dice).reshape(nrows, ncols)\n",
    "rolls"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3924ba0",
   "metadata": {},
   "source": [
    "What do the different distribution methods do?\n",
    "We'll focus on three tests for these specific purposes:\n",
    "\n",
    "chi2: to compare two categorical variables\n",
    "pearson r: to compare two continuous variables\n",
    "t-test: to compare one categorical and one continuous variable\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88c4ae2d",
   "metadata": {},
   "source": [
    "RSV Random Values\n",
    "We can generate random values based on the distribution with the rvs method. We can pass\n",
    "\n",
    "no arguments to get a single random value\n",
    "a single integer to get that many random values\n",
    "a tuple with the dimensions of a matrix of random values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edc57fad",
   "metadata": {},
   "source": [
    "PMF / PDF\n",
    "The probability mass function (pmf) (probability density function (pdf) for continuous distributions) is a function that gives us the probability of any single outcome. For example, we could use the pmf to give us the probability of rolling a 3 with our dice rolling distribution:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2052da0f",
   "metadata": {},
   "source": [
    "CDF / PPF\n",
    "The cumulative density function tells us the likelihood of a single outcome or all the results below it. For our dice rolling example, this might be something like \"what is the probability of rolling a 3 or lower?\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a1951a9",
   "metadata": {},
   "source": [
    "The percent point function (ppf) (also known as the quantile function) can be thought of as the inverse of the cdf.\n",
    "\n",
    "The ppf accepts a probability, and gives us the value that is associate with that probability:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce7d555c",
   "metadata": {},
   "source": [
    "The survival function (sf) tells us what the probability of our random variable falling above a certain value is. This is the same as 1 minus the cdf of the same value.\n",
    "\n",
    "We can use this to answer questions like: \"What is the likelihood we roll a value higher than 4?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17f98369",
   "metadata": {},
   "source": [
    "Like the ppf, the inverse survival function (isf) will give us a value when we provide a probability.\n",
    "\n",
    "For example: \"There is a 1/3 chance a dice roll will be higher than what value?\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b787940f",
   "metadata": {},
   "source": [
    "How to pick a distribution type for a given scenario?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0902fb6f",
   "metadata": {},
   "source": [
    "Binomial Distribution\n",
    "Binomial distributions are all about determining a binary outcome of an event. Success/failure, for example\n",
    "The binomial distribution lets us model the number of successes after a number of trials, given a certain probability of success. The classic example of this is the number of heads you would expect to see after flipping a coin a certain number of times.\n",
    "\n",
    "A binomial distribution is defined by a number of trials, and a probability of success. These two pieces of information are what we need in order to model a problem with the binomial distribution.\n",
    "\n",
    "The binomial distribution assumes that each trial is independent of the others.\n",
    "\n",
    "Let's take an example:\n",
    "\n",
    "You are taking a multiple choice test consisting of 30 questions that you forgot to study for. Each question has 4 possible answers and you will choose one at random. What is the probability you get more than 10 of the questions right?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edb10402",
   "metadata": {},
   "source": [
    "Normal Distribution Normal distributions model a continuous random variable.\n",
    "\n",
    "The normal distribution models a continuous random variable where the further away from the mean you are, the less likely the outcome. This is commonly referred to as the \"bell curve\", and many continous variables tend to follow a normal distribution.\n",
    "\n",
    "A normal distribution is defined by a mean and a standard deviation. The standard normal distribution is a normal distribution with a mean of 0 and standard deviation of 1.\n",
    "\n",
    "Suppose that a store's daily sales are normally distributed with a mean of 12,000 dollars and standard deviation of 2000 dollars. How much would the daily sales have to be to be in the top 10% of all days?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36cbe9a0",
   "metadata": {},
   "source": [
    "Poisson Distribution Poisson distributions a certain amount of events occuring over a time interval\n",
    "\n",
    "The poisson distribution lets us model a situation where a certain number of events happen over a specified time interval1. The number of events that happen is a discrete measure, and this distribution can tell us the likelihood of a certain number of events occuring over the time period.\n",
    "\n",
    "The poisson distribution assumes that the events are indpendent of each other and independent of the time since the last event. We must also know the average rate to use a poisson distribution.\n",
    "\n",
    "Some examples of real-world processes that can be modeled with a poisson distribution are:\n",
    "\n",
    "The number of emails sent by a mail server in a day\n",
    "The number of phone calls received by a call center per hour\n",
    "The number of decay events per second from a radioactive source\n",
    "Let's dive into a specific example:\n",
    "\n",
    "Codeup knows that, on average, students consume 5 lbs of coffee per week. How likely is it that the coffee consumption for this week is only 3 lbs?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd32dfe5",
   "metadata": {},
   "source": [
    "Uniform distributions have equal likelyhoods amont all outcomes, like a fair coin."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d4da1ad",
   "metadata": {},
   "source": [
    "When to use which hypothesis test?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1941acc6",
   "metadata": {},
   "source": [
    "Notice the variables and their types in these questions...\n",
    "\n",
    "Do those who churn (has_churned, boolean) spend more each month (avg_monthly_spend, numeric) than those who do not churn?\n",
    "\n",
    "Are customers with Fiber (has_fiber, boolean) more likely to churn (has_churned, boolean) that those without?\n",
    "\n",
    "Are sr. citizens (is_senior_citizen, boolean) more likely to churn (has_churned, boolean)?\n",
    "\n",
    "Are customers without autopayment (has_autopayment, boolean) more likely to churn (has_churned, boolean)?\n",
    "\n",
    "Do customers who churn (has_churned, boolean) have lower tenure (tenure_months, numeric)?\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and total charges (ttl_charges, numeric)?\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and average monthly charges (avg_monthly_charges, numeric)?\n",
    "\n",
    "The types of tests we run depends on the question and data types:\n",
    "\n",
    "Do those who churn (has_churned, boolean) spend more each month (avg_monthly_spend, numeric) than those who do not churn? (boolean x numeric: comparison of means (t-test) across the 2 groups)\n",
    "\n",
    "Are customers with Fiber (has_fiber, boolean) more likely to churn (has_churned, boolean) that those without? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Are sr. citizens (is_senior_citizen, boolean) more likely to churn (has_churned, boolean)? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Are customers without autopayment (has_autopayment, boolean) more likely to churn (has_churned, boolean)? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Do customers who churn (has_churned, boolean) have lower tenure (tenure_months, numeric)? (boolean x numeric: comparison of means (t-test) across the 2 groups)\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and total charges (ttl_charges, numeric)? (numeric x numeric: linear correlation between two continuous values, does one affect the other. (pearson's correlation))\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and average monthly charges (avg_monthly_charges, numeric)? (numeric x numeric: linear correlation between two continuous values, does one affect the other. (pearson's correlation))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23ab7267",
   "metadata": {},
   "source": [
    "How to write the null and alternative hypothesis for your test?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6352e336",
   "metadata": {},
   "source": [
    "Assumptions that each test has about the data?\n",
    "https://ds.codeup.com/stats/compare-means/#comparing-tests-that-compare-means"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a3fec06",
   "metadata": {},
   "source": [
    "Type I and Type II errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9505ccd9",
   "metadata": {},
   "source": [
    "One Sample T-Test\n",
    "Goal: Compare observed mean to theoretical one.\n",
    "\n",
    "1. Plot Distributions (i.e. Histograms!)\n",
    "2. Establish Hypotheses\n",
    "H0: Mean of monthly charges of churned customers <= Mean of monthly charges of all customers\n",
    "HA: Mean of monthly charges of churned customers > Mean of monthly charges of all customers\n",
    "\n",
    "Null Hypothesis\tH0μobs=μth\n",
    "Alternative Hypothesis (2-tail, significantly different)\tHaμobs!=μth\n",
    "Alternative Hypothesis (1-tail, significantly smaller)\tHaμobs<μth\n",
    "Alternative Hypothesis (1-tail, significantly larger)\tHaμobs>μth\n",
    "\n",
    "\n",
    "3. Set Significance Level: α=.05\n",
    "4. Set Alpha\n",
    "5. Verify Assumptions: Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT)\n",
    "6. Compute test statistic and probability (t-statistic & p-value) using scipy.stats.ttest_1samp.\n",
    "7. Decide. For a 2-tailed test, we take the p-value as is. For a 1-tailed test, we evaluate \n",
    "p/2<α and t>0 (to test if higher), and of a less-than test when p/2<α and t<0.\n",
    "8. Decide"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a17a464",
   "metadata": {},
   "source": [
    "\n",
    "Independent T-Test (a.k.a. Two Sample T-Test)\n",
    "Goal: Compare mean of group a to mean of group b.\n",
    "\n",
    "Plot Distributions (i.e. Histograms!)\n",
    "\n",
    "Establish Hypotheses\n",
    "H0: Mean of monthly charges of churned customers <= Mean of monthly charges of customers who haven't churned\n",
    "Ha: Mean of monthly charges of churned customers > Mean of monthly charges of customers who haven't churned\n",
    "\n",
    "Null Hypothesis\tH0μa==μb\n",
    "Alternative Hypothesis (2-tail, significantly different)\tHaμa!=μb\n",
    "Alternative Hypothesis (1-tail, a is significantly smaller than b)\tHaμa<μb\n",
    "Alternative Hypothesis (1-tail, a is significantly larger than b)\tHaμa<μb\n",
    "\n",
    "\n",
    "Set Significance Level: \n",
    "α\n",
    "=\n",
    ".05\n",
    "\n",
    "Verify Assumptions:\n",
    "-Independent Samples (n.a. for 1-sample t-test). YES! no observations in the churn sample exist in the no-churn sample.\n",
    "-Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT). YES! Plenty of observations\n",
    "-Equal Variances (the scipy methods we will use has an argument to handle when variances aren't equal).\n",
    "\n",
    "Compute test statistic and probability (t-statistic & p-value) using scipy.stats.ttest_ind\n",
    "\n",
    "Decide.\n",
    "print(\"is p/2 < alpha? \", p / 2 < alpha)\n",
    "print(\"is t > 0? \", t > 0)\n",
    "is p/2 < alpha?  True\n",
    "is t > 0?  True\n",
    "if p / 2 > alpha:\n",
    "    print(\"We fail to reject $H_{0}$\")\n",
    "elif t < 0:\n",
    "    print(\"We fail to reject $H_{0}$\")\n",
    "else:\n",
    "    print(\"We reject $H_{0}$\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86a5c6b5",
   "metadata": {},
   "source": [
    "ANOVA Analysis of Variance\n",
    "Goal: Compare means of groups a, b & c.\n",
    "\n",
    "Plot Distributions (i.e. Histograms!)\n",
    "\n",
    "Establish Hypotheses\n",
    "\n",
    "Null Hypothesis\t\n",
    "H\n",
    "0\n",
    "μ\n",
    "a\n",
    "==\n",
    "μ\n",
    "b\n",
    "==\n",
    "μ\n",
    "c\n",
    "Alternative Hypothesis (significantly different)\t\n",
    "H\n",
    "a\n",
    "μ\n",
    "a\n",
    "!\n",
    "=\n",
    "μ\n",
    "b\n",
    "!\n",
    "=\n",
    "μ\n",
    "c\n",
    "Set Significance Level: \n",
    "α\n",
    "=\n",
    ".05\n",
    "\n",
    "Verify Assumptions:\n",
    "\n",
    "Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT)\n",
    "Independent samples\n",
    "Equal Variances\n",
    "Compute test statistic and probability (t-statistic & p-value) using scipy.stats.f_oneway\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Independent samples: YES!\n",
    "Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT). YES! the distributions are mostly normal\n",
    "Equal Variances: YES! The variance is very small so the differences are minor.\n",
    "\n",
    "\n",
    "Hypothesis\n",
    "\n",
    "H\n",
    "0\n",
    ": hp is the same across all origins\n",
    "\n",
    "H\n",
    "a\n",
    ": hp is not the same across all origins\n",
    "\n",
    "Significance Level\n",
    "\n",
    "α\n",
    " is already set to .05\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Normal: yes!\n",
    "Independent: yes!\n",
    "Variance: ?\n",
    "\n",
    "Looking at the variances, they are very different, so I will move to a 2-sample, independent t-test comparing usa made cars vs. non-usa made cars.\n",
    "\n",
    "\n",
    "Hypothesis\n",
    "\n",
    "H\n",
    "0\n",
    ": usa origin cars' hp equals non-usa origin cars' hp\n",
    "\n",
    "H\n",
    "a\n",
    ": usa origin cars' hp does not equal non-usa origin cars' hp\n",
    "\n",
    "Significance Level\n",
    "\n",
    "α\n",
    " is already set to .05\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Normal: yes!\n",
    "Independent: yes!\n",
    "Variance: ?\n",
    "\n",
    "Decide\n",
    "\n",
    "is p-value less than alpha? YES, then Reject null hypothesis. The hp of usa cars vs. non-usa cars is significantly different.\n",
    "\n",
    "stats.kruskal(usa_hp, japan_hp, eu_hp)\n",
    "\n",
    "KruskalResult(statistic=105.59475799843663, pvalue=1.1759521262123952e-23)\n",
    "Using Kruskal-Wallis test, non-parametric test for ANOVA, also shows us that the mean HP of the cars from the 3 origins is significantly different."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e059eec",
   "metadata": {},
   "source": [
    "Correlation\n",
    "Correlation tests are used to check if two samples are related. They are often used for feature selection and multivariate analysis in data preprocessing and exploration.\n",
    "\n",
    "Pearson's Correlation Coefficient\n",
    "The goal of this test is to answer the question: do two samples have a linear relationship?\n",
    "\n",
    "To answer this question, we will take the following steps:\n",
    "\n",
    "The Easy Way\n",
    "All of the work that we did above is also provided by scipy's stats module in it's pearsonr function.\n",
    "\n",
    "\n",
    "corr, p = stats.pearsonr(x, y)\n",
    "corr, p\n",
    "\n",
    " \n",
    " Correlation Gotchas\n",
    "When working with correlation, keep in mind:\n",
    "\n",
    "Correlation is not causality.\n",
    "Correlation measures linear relationship between the 2 variables. However, there may be other types of relationships, such as a quadratic or absolute value relationship.\n",
    "Correlations can be misleading when confounding variables are ignored.\n",
    "Correlation tells you nothing about how large the relationship is.\n",
    "Correlation is Not Causation\n",
    "Correlation means that two variables are associated, but doesn't tell us whether one causes the other or not.\n",
    "Confounding Variables\n",
    "We must be careful because correlation doesn't tell the whole story of a dataset. That is, correlation just looks at two variables in isolation, and doesn't account for any others. For example, a certain subgroup could have a strong correlation while another does not, or a third variable could be influencing both of the variables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ddb72ed",
   "metadata": {},
   "source": [
    "What about non-linear correlations between variables?\n",
    "Use Spearman's R, https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html for a nonparametric test of linearity, as long as we have monotonicity.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcadfda3",
   "metadata": {},
   "source": [
    "Comparing Group Membership\n",
    "The \n",
    "χ\n",
    "2\n",
    " test can be used to compare two categorical variables and helps us answer questions like:\n",
    "\n",
    "Is whether or not a customer churns independent of their subscription plan?\n",
    "Are doctors less likely to smoke?\n",
    "Does playing on the home field give a soccer team an advantage?\n",
    "In this lesson we will dive into how the test is performed.\n",
    "\n",
    "The \n",
    "χ\n",
    "2\n",
    " Contingency Table Test\n",
    "The \n",
    "χ\n",
    "2\n",
    " test can be also be used in several other ways, but we will use what is referred to as the contingency table test, which lets us test the hypothesis that one group is independent of another. To do this, we will\n",
    "\n",
    "Calculate the theoretical expected values\n",
    "\n",
    "Find the actual observed values\n",
    "\n",
    "Calculate a test-statistic and p-value based on the two tables above\n",
    "\n",
    "Specifically, our test-statistic, \n",
    "χ\n",
    "2\n",
    " is given by:\n",
    "\n",
    "χ\n",
    "2\n",
    "=\n",
    "∑\n",
    "(\n",
    "O\n",
    "−\n",
    "E\n",
    ")\n",
    "2\n",
    "E\n",
    "Where \n",
    "O\n",
    " is the observed values, and \n",
    "E\n",
    " is the expected values.\n",
    "\n",
    "Calculating Expected Proportions\n",
    "To begin with, we will calculate the values we would expect to see if the two groups are independent.\n",
    "\n",
    "For each subgroup, we calculate the proportion of the total that it is, then multiply each subgroups proportion by the proportion from every other subgroup to determine the expected values.\n",
    "\n",
    "To find the overall proportions, we multiply all the combinations of proportions together.\n",
    "\n",
    "For example, to find the expected proportion of automatic drive cars with 4-wheel drive, we would multiply those two proportions together.\n",
    "\n",
    ".67\n",
    "∗\n",
    ".44\n",
    "=\n",
    ".2984\n",
    "So we would expect about 29.84% of the total cars to be automatic and 4-wheel drive.\n",
    "\n",
    "Below we show some code that will loop through all of the proportions and perform this calculation for all combinations of groups.\n",
    "\n",
    "If we wanted to convert these proportions to expected number of values, we can multiply by the total number of observations:\n",
    "\n",
    "\n",
    "expected *= n\n",
    "expected\n",
    "\n",
    "Now we have the expected proportions, we need to calculate the actual proportions so that we can compare them. to do this, we'll use the crosstab function from pandas.\n",
    "Now we can calculate our test statistic, \n",
    "χ\n",
    "2\n",
    "\n",
    "\n",
    "chi2 = ((observed - expected)**2 / expected).values.sum()\n",
    "chi2\n",
    "\n",
    "We also need to find our degrees of freedom for the distribution. The degrees of freedom are given by:\n",
    "\n",
    "(\n",
    "nrows\n",
    "−\n",
    "1\n",
    ")\n",
    "×\n",
    "(\n",
    "ncols\n",
    "−\n",
    "1\n",
    ")\n",
    "Where nrows and ncols are the number of rows and columns in our contingency table.\n",
    "\n",
    "\n",
    "nrows, ncols = observed.shape\n",
    "\n",
    "degrees_of_freedom = (nrows - 1) * (ncols - 1)\n",
    "Now, based on the test statistic and degrees of freedom, we could lookup the corresponding p-value from a pre-calculated table, or use scipy's chi2 distribution.\n",
    "\n",
    "\n",
    "stats.chi2(degrees_of_freedom).sf(chi2)\n",
    "\n",
    "0.20838152534979645\n",
    "With this high of a p-value, we fail to reject our null hypothesis.\n",
    "\n",
    "The Easy Way\n",
    "We can also give our observed values to the chi2_contingency function from scipy's stats module to make all the calculations for us."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
