{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bdf85f17",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "import statistics\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47ae17d5",
   "metadata": {},
   "source": [
    "How to make a distribution (or simulate it) and use the distribution methods on them?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "50c0a0b0",
   "metadata": {},
   "source": [
    "n_trials = nrows = 10_000\n",
    "n_dice = ncols = 3\n",
    "\n",
    "rolls = np.random.choice([1, 2, 3, 4, 5, 6], n_trials * n_dice).reshape(nrows, ncols)\n",
    "rolls"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3924ba0",
   "metadata": {},
   "source": [
    "What do the different distribution methods do?\n",
    "We'll focus on three tests for these specific purposes:\n",
    "\n",
    "chi2: to compare two categorical variables\n",
    "pearson r: to compare two continuous variables\n",
    "t-test: to compare one categorical and one continuous variable\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88c4ae2d",
   "metadata": {},
   "source": [
    "RSV Random Values\n",
    "We can generate random values based on the distribution with the rvs method. We can pass\n",
    "\n",
    "no arguments to get a single random value\n",
    "a single integer to get that many random values\n",
    "a tuple with the dimensions of a matrix of random values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edc57fad",
   "metadata": {},
   "source": [
    "PMF / PDF\n",
    "The probability mass function (pmf) (probability density function (pdf) for continuous distributions) is a function that gives us the probability of any single outcome. For example, we could use the pmf to give us the probability of rolling a 3 with our dice rolling distribution:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2052da0f",
   "metadata": {},
   "source": [
    "CDF / PPF\n",
    "The cumulative density function tells us the likelihood of a single outcome or all the results below it. For our dice rolling example, this might be something like \"what is the probability of rolling a 3 or lower?\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a1951a9",
   "metadata": {},
   "source": [
    "The percent point function (ppf) (also known as the quantile function) can be thought of as the inverse of the cdf.\n",
    "\n",
    "The ppf accepts a probability, and gives us the value that is associate with that probability:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce7d555c",
   "metadata": {},
   "source": [
    "The survival function (sf) tells us what the probability of our random variable falling above a certain value is. This is the same as 1 minus the cdf of the same value.\n",
    "\n",
    "We can use this to answer questions like: \"What is the likelihood we roll a value higher than 4?\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17f98369",
   "metadata": {},
   "source": [
    "Like the ppf, the inverse survival function (isf) will give us a value when we provide a probability.\n",
    "\n",
    "For example: \"There is a 1/3 chance a dice roll will be higher than what value?\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "b787940f",
   "metadata": {},
   "source": [
    "How to pick a distribution type for a given scenario?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0902fb6f",
   "metadata": {},
   "source": [
    "Binomial Distribution\n",
    "Binomial distributions are all about determining a binary outcome of an event. Success/failure, for example\n",
    "The binomial distribution lets us model the number of successes after a number of trials, given a certain probability of success. The classic example of this is the number of heads you would expect to see after flipping a coin a certain number of times.\n",
    "\n",
    "A binomial distribution is defined by a number of trials, and a probability of success. These two pieces of information are what we need in order to model a problem with the binomial distribution.\n",
    "\n",
    "The binomial distribution assumes that each trial is independent of the others.\n",
    "\n",
    "Let's take an example:\n",
    "\n",
    "You are taking a multiple choice test consisting of 30 questions that you forgot to study for. Each question has 4 possible answers and you will choose one at random. What is the probability you get more than 10 of the questions right?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edb10402",
   "metadata": {},
   "source": [
    "Normal Distribution Normal distributions model a continuous random variable.\n",
    "\n",
    "The normal distribution models a continuous random variable where the further away from the mean you are, the less likely the outcome. This is commonly referred to as the \"bell curve\", and many continous variables tend to follow a normal distribution.\n",
    "\n",
    "A normal distribution is defined by a mean and a standard deviation. The standard normal distribution is a normal distribution with a mean of 0 and standard deviation of 1.\n",
    "\n",
    "Suppose that a store's daily sales are normally distributed with a mean of 12,000 dollars and standard deviation of 2000 dollars. How much would the daily sales have to be to be in the top 10% of all days?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36cbe9a0",
   "metadata": {},
   "source": [
    "Poisson Distribution Poisson distributions a certain amount of events occuring over a time interval\n",
    "\n",
    "The poisson distribution lets us model a situation where a certain number of events happen over a specified time interval1. The number of events that happen is a discrete measure, and this distribution can tell us the likelihood of a certain number of events occuring over the time period.\n",
    "\n",
    "The poisson distribution assumes that the events are indpendent of each other and independent of the time since the last event. We must also know the average rate to use a poisson distribution.\n",
    "\n",
    "Some examples of real-world processes that can be modeled with a poisson distribution are:\n",
    "\n",
    "The number of emails sent by a mail server in a day\n",
    "The number of phone calls received by a call center per hour\n",
    "The number of decay events per second from a radioactive source\n",
    "Let's dive into a specific example:\n",
    "\n",
    "Codeup knows that, on average, students consume 5 lbs of coffee per week. How likely is it that the coffee consumption for this week is only 3 lbs?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd32dfe5",
   "metadata": {},
   "source": [
    "Uniform distributions have equal likelyhoods amont all outcomes, like a fair coin."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d4da1ad",
   "metadata": {},
   "source": [
    "When to use which hypothesis test?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1941acc6",
   "metadata": {},
   "source": [
    "Notice the variables and their types in these questions...\n",
    "\n",
    "Do those who churn (has_churned, boolean) spend more each month (avg_monthly_spend, numeric) than those who do not churn?\n",
    "\n",
    "Are customers with Fiber (has_fiber, boolean) more likely to churn (has_churned, boolean) that those without?\n",
    "\n",
    "Are sr. citizens (is_senior_citizen, boolean) more likely to churn (has_churned, boolean)?\n",
    "\n",
    "Are customers without autopayment (has_autopayment, boolean) more likely to churn (has_churned, boolean)?\n",
    "\n",
    "Do customers who churn (has_churned, boolean) have lower tenure (tenure_months, numeric)?\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and total charges (ttl_charges, numeric)?\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and average monthly charges (avg_monthly_charges, numeric)?\n",
    "\n",
    "The types of tests we run depends on the question and data types:\n",
    "\n",
    "Do those who churn (has_churned, boolean) spend more each month (avg_monthly_spend, numeric) than those who do not churn? (boolean x numeric: comparison of means (t-test) across the 2 groups)\n",
    "\n",
    "Are customers with Fiber (has_fiber, boolean) more likely to churn (has_churned, boolean) that those without? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Are sr. citizens (is_senior_citizen, boolean) more likely to churn (has_churned, boolean)? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Are customers without autopayment (has_autopayment, boolean) more likely to churn (has_churned, boolean)? (boolean x boolean: comparison of proportions/relationships)\n",
    "\n",
    "Do customers who churn (has_churned, boolean) have lower tenure (tenure_months, numeric)? (boolean x numeric: comparison of means (t-test) across the 2 groups)\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and total charges (ttl_charges, numeric)? (numeric x numeric: linear correlation between two continuous values, does one affect the other. (pearson's correlation))\n",
    "\n",
    "Is there a linear relationship between tenure (tenure_months, numeric) and average monthly charges (avg_monthly_charges, numeric)? (numeric x numeric: linear correlation between two continuous values, does one affect the other. (pearson's correlation))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23ab7267",
   "metadata": {},
   "source": [
    "How to write the null and alternative hypothesis for your test?\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6352e336",
   "metadata": {},
   "source": [
    "Assumptions that each test has about the data?\n",
    "https://ds.codeup.com/stats/compare-means/#comparing-tests-that-compare-means"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a3fec06",
   "metadata": {},
   "source": [
    "Type I and Type II errors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9505ccd9",
   "metadata": {},
   "source": [
    "One Sample T-Test\n",
    "Goal: Compare observed mean to theoretical one.\n",
    "\n",
    "1. Plot Distributions (i.e. Histograms!)\n",
    "2. Establish Hypotheses\n",
    "H0: Mean of monthly charges of churned customers <= Mean of monthly charges of all customers\n",
    "HA: Mean of monthly charges of churned customers > Mean of monthly charges of all customers\n",
    "\n",
    "Null Hypothesis\tH0μobs=μth\n",
    "Alternative Hypothesis (2-tail, significantly different)\tHaμobs!=μth\n",
    "Alternative Hypothesis (1-tail, significantly smaller)\tHaμobs<μth\n",
    "Alternative Hypothesis (1-tail, significantly larger)\tHaμobs>μth\n",
    "\n",
    "\n",
    "3. Set Significance Level: α=.05\n",
    "4. Set Alpha\n",
    "5. Verify Assumptions: Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT)\n",
    "6. Compute test statistic and probability (t-statistic & p-value) using scipy.stats.ttest_1samp.\n",
    "7. Decide. For a 2-tailed test, we take the p-value as is. For a 1-tailed test, we evaluate \n",
    "p/2<α and t>0 (to test if higher), and of a less-than test when p/2<α and t<0.\n",
    "8. Decide"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a17a464",
   "metadata": {},
   "source": [
    "\n",
    "Independent T-Test (a.k.a. Two Sample T-Test)\n",
    "Goal: Compare mean of group a to mean of group b.\n",
    "\n",
    "Plot Distributions (i.e. Histograms!)\n",
    "\n",
    "Establish Hypotheses\n",
    "H0: Mean of monthly charges of churned customers <= Mean of monthly charges of customers who haven't churned\n",
    "Ha: Mean of monthly charges of churned customers > Mean of monthly charges of customers who haven't churned\n",
    "\n",
    "Null Hypothesis\tH0μa==μb\n",
    "Alternative Hypothesis (2-tail, significantly different)\tHaμa!=μb\n",
    "Alternative Hypothesis (1-tail, a is significantly smaller than b)\tHaμa<μb\n",
    "Alternative Hypothesis (1-tail, a is significantly larger than b)\tHaμa<μb\n",
    "\n",
    "\n",
    "Set Significance Level: \n",
    "α\n",
    "=\n",
    ".05\n",
    "\n",
    "Verify Assumptions:\n",
    "-Independent Samples (n.a. for 1-sample t-test). YES! no observations in the churn sample exist in the no-churn sample.\n",
    "-Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT). YES! Plenty of observations\n",
    "-Equal Variances (the scipy methods we will use has an argument to handle when variances aren't equal).\n",
    "\n",
    "Compute test statistic and probability (t-statistic & p-value) using scipy.stats.ttest_ind\n",
    "\n",
    "Decide.\n",
    "print(\"is p/2 < alpha? \", p / 2 < alpha)\n",
    "print(\"is t > 0? \", t > 0)\n",
    "is p/2 < alpha?  True\n",
    "is t > 0?  True\n",
    "if p / 2 > alpha:\n",
    "    print(\"We fail to reject $H_{0}$\")\n",
    "elif t < 0:\n",
    "    print(\"We fail to reject $H_{0}$\")\n",
    "else:\n",
    "    print(\"We reject $H_{0}$\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86a5c6b5",
   "metadata": {},
   "source": [
    "ANOVA Analysis of Variance\n",
    "Goal: Compare means of groups a, b & c.\n",
    "\n",
    "Plot Distributions (i.e. Histograms!)\n",
    "\n",
    "Establish Hypotheses\n",
    "\n",
    "Null Hypothesis\t\n",
    "H\n",
    "0\n",
    "μ\n",
    "a\n",
    "==\n",
    "μ\n",
    "b\n",
    "==\n",
    "μ\n",
    "c\n",
    "Alternative Hypothesis (significantly different)\t\n",
    "H\n",
    "a\n",
    "μ\n",
    "a\n",
    "!\n",
    "=\n",
    "μ\n",
    "b\n",
    "!\n",
    "=\n",
    "μ\n",
    "c\n",
    "Set Significance Level: \n",
    "α\n",
    "=\n",
    ".05\n",
    "\n",
    "Verify Assumptions:\n",
    "\n",
    "Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT)\n",
    "Independent samples\n",
    "Equal Variances\n",
    "Compute test statistic and probability (t-statistic & p-value) using scipy.stats.f_oneway\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Independent samples: YES!\n",
    "Normal Distribution, or at least 30 observations and \"kinda\" normal. The more observations you have, the less \"normal\" it needs to appear. (CLT). YES! the distributions are mostly normal\n",
    "Equal Variances: YES! The variance is very small so the differences are minor.\n",
    "\n",
    "\n",
    "Hypothesis\n",
    "\n",
    "H\n",
    "0\n",
    ": hp is the same across all origins\n",
    "\n",
    "H\n",
    "a\n",
    ": hp is not the same across all origins\n",
    "\n",
    "Significance Level\n",
    "\n",
    "α\n",
    " is already set to .05\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Normal: yes!\n",
    "Independent: yes!\n",
    "Variance: ?\n",
    "\n",
    "Looking at the variances, they are very different, so I will move to a 2-sample, independent t-test comparing usa made cars vs. non-usa made cars.\n",
    "\n",
    "\n",
    "Hypothesis\n",
    "\n",
    "H\n",
    "0\n",
    ": usa origin cars' hp equals non-usa origin cars' hp\n",
    "\n",
    "H\n",
    "a\n",
    ": usa origin cars' hp does not equal non-usa origin cars' hp\n",
    "\n",
    "Significance Level\n",
    "\n",
    "α\n",
    " is already set to .05\n",
    "\n",
    "Verify Assumptions\n",
    "\n",
    "Normal: yes!\n",
    "Independent: yes!\n",
    "Variance: ?\n",
    "\n",
    "Decide\n",
    "\n",
    "is p-value less than alpha? YES, then Reject null hypothesis. The hp of usa cars vs. non-usa cars is significantly different.\n",
    "\n",
    "stats.kruskal(usa_hp, japan_hp, eu_hp)\n",
    "\n",
    "KruskalResult(statistic=105.59475799843663, pvalue=1.1759521262123952e-23)\n",
    "Using Kruskal-Wallis test, non-parametric test for ANOVA, also shows us that the mean HP of the cars from the 3 origins is significantly different."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e059eec",
   "metadata": {},
   "source": [
    "Correlation\n",
    "Correlation tests are used to check if two samples are related. They are often used for feature selection and multivariate analysis in data preprocessing and exploration.\n",
    "\n",
    "Pearson's Correlation Coefficient\n",
    "The goal of this test is to answer the question: do two samples have a linear relationship?\n",
    "\n",
    "To answer this question, we will take the following steps:\n",
    "\n",
    "The Easy Way\n",
    "All of the work that we did above is also provided by scipy's stats module in it's pearsonr function.\n",
    "\n",
    "\n",
    "corr, p = stats.pearsonr(x, y)\n",
    "corr, p\n",
    "\n",
    " \n",
    " Correlation Gotchas\n",
    "When working with correlation, keep in mind:\n",
    "\n",
    "Correlation is not causality.\n",
    "Correlation measures linear relationship between the 2 variables. However, there may be other types of relationships, such as a quadratic or absolute value relationship.\n",
    "Correlations can be misleading when confounding variables are ignored.\n",
    "Correlation tells you nothing about how large the relationship is.\n",
    "Correlation is Not Causation\n",
    "Correlation means that two variables are associated, but doesn't tell us whether one causes the other or not.\n",
    "Confounding Variables\n",
    "We must be careful because correlation doesn't tell the whole story of a dataset. That is, correlation just looks at two variables in isolation, and doesn't account for any others. For example, a certain subgroup could have a strong correlation while another does not, or a third variable could be influencing both of the variables."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ddb72ed",
   "metadata": {},
   "source": [
    "What about non-linear correlations between variables?\n",
    "Use Spearman's R, https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html for a nonparametric test of linearity, as long as we have monotonicity.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcadfda3",
   "metadata": {},
   "source": [
    "Comparing Group Membership\n",
    "The \n",
    "χ\n",
    "2\n",
    " test can be used to compare two categorical variables and helps us answer questions like:\n",
    "\n",
    "Is whether or not a customer churns independent of their subscription plan?\n",
    "Are doctors less likely to smoke?\n",
    "Does playing on the home field give a soccer team an advantage?\n",
    "In this lesson we will dive into how the test is performed.\n",
    "\n",
    "The \n",
    "χ\n",
    "2\n",
    " Contingency Table Test\n",
    "The \n",
    "χ\n",
    "2\n",
    " test can be also be used in several other ways, but we will use what is referred to as the contingency table test, which lets us test the hypothesis that one group is independent of another. To do this, we will\n",
    "\n",
    "Calculate the theoretical expected values\n",
    "\n",
    "Find the actual observed values\n",
    "\n",
    "Calculate a test-statistic and p-value based on the two tables above\n",
    "\n",
    "Specifically, our test-statistic, \n",
    "χ\n",
    "2\n",
    " is given by:\n",
    "\n",
    "χ\n",
    "2\n",
    "=\n",
    "∑\n",
    "(\n",
    "O\n",
    "−\n",
    "E\n",
    ")\n",
    "2\n",
    "E\n",
    "Where \n",
    "O\n",
    " is the observed values, and \n",
    "E\n",
    " is the expected values.\n",
    "\n",
    "Calculating Expected Proportions\n",
    "To begin with, we will calculate the values we would expect to see if the two groups are independent.\n",
    "\n",
    "For each subgroup, we calculate the proportion of the total that it is, then multiply each subgroups proportion by the proportion from every other subgroup to determine the expected values.\n",
    "\n",
    "To find the overall proportions, we multiply all the combinations of proportions together.\n",
    "\n",
    "For example, to find the expected proportion of automatic drive cars with 4-wheel drive, we would multiply those two proportions together.\n",
    "\n",
    ".67\n",
    "∗\n",
    ".44\n",
    "=\n",
    ".2984\n",
    "So we would expect about 29.84% of the total cars to be automatic and 4-wheel drive.\n",
    "\n",
    "Below we show some code that will loop through all of the proportions and perform this calculation for all combinations of groups.\n",
    "\n",
    "If we wanted to convert these proportions to expected number of values, we can multiply by the total number of observations:\n",
    "\n",
    "\n",
    "expected *= n\n",
    "expected\n",
    "\n",
    "Now we have the expected proportions, we need to calculate the actual proportions so that we can compare them. to do this, we'll use the crosstab function from pandas.\n",
    "Now we can calculate our test statistic, \n",
    "χ\n",
    "2\n",
    "\n",
    "\n",
    "chi2 = ((observed - expected)**2 / expected).values.sum()\n",
    "chi2\n",
    "\n",
    "We also need to find our degrees of freedom for the distribution. The degrees of freedom are given by:\n",
    "\n",
    "(\n",
    "nrows\n",
    "−\n",
    "1\n",
    ")\n",
    "×\n",
    "(\n",
    "ncols\n",
    "−\n",
    "1\n",
    ")\n",
    "Where nrows and ncols are the number of rows and columns in our contingency table.\n",
    "\n",
    "\n",
    "nrows, ncols = observed.shape\n",
    "\n",
    "degrees_of_freedom = (nrows - 1) * (ncols - 1)\n",
    "Now, based on the test statistic and degrees of freedom, we could lookup the corresponding p-value from a pre-calculated table, or use scipy's chi2 distribution.\n",
    "\n",
    "\n",
    "stats.chi2(degrees_of_freedom).sf(chi2)\n",
    "\n",
    "0.20838152534979645\n",
    "With this high of a p-value, we fail to reject our null hypothesis.\n",
    "\n",
    "The Easy Way\n",
    "We can also give our observed values to the chi2_contingency function from scipy's stats module to make all the calculations for us."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1f05f4a",
   "metadata": {},
   "source": [
    "We'll focus on three tests for these specific purposes:\n",
    "\n",
    "chi2: to compare two categorical variables\n",
    "pearson r: to compare two continuous variables\n",
    "t-test: to compare one categorical and one continuous variable\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84012dab",
   "metadata": {},
   "source": [
    "chi2\n",
    "We use a chi2 test to compare two categorical variables. For this example, we will compare the sex variable with the smoker column. Our null hypothesis is that membership in these groups is independent, more formally:\n",
    "\n",
    "H\n",
    "0\n",
    ": sex is indep of whether or not someone is a smoker\n",
    "\n",
    "First we need to generate a contingency table, which is another word for a cross tabulation, and can easily be generated with pandas."
   ]
  },
  {
   "cell_type": "raw",
   "id": "659dd160",
   "metadata": {},
   "source": [
    "The way the chi2 test works is to compare the actual contingency table of the actual values against the table that we would predict to be the case if group membership is independent. When we perform the test, one of the returned values will be the expected values in the contingency table.\n",
    "\n",
    "To perform the test, we simply pass the contingency table that we created with pandas to the chi2_contingency function from scipy."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5256695e",
   "metadata": {},
   "source": [
    "The function returns several values:\n",
    "\n",
    "the chi2 test statistic\n",
    "the p value\n",
    "the degrees of freedom\n",
    "the matrix of expected values\n",
    "We'll focus in on the p value and the matrix of expected values:\n",
    "\n",
    "_, p, _, expected = test_results\n",
    "Now we can look at p to decide whether to reject / fail to reject H0.\n",
    "\n",
    "\n",
    "p\n",
    "\n",
    "1.0\n",
    "With such a high p-value, we fail to reject the null hypothesis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d69bc553",
   "metadata": {},
   "source": [
    "Less formally, it seems as though two groups are independent of each other. We can see an intuitive proof of this by comparing the expected values agains what we actually observed:\n",
    "\n",
    "\n",
    "# Here we'll do some data frame manipulation with pandas to get the two tables\n",
    "# into a more comparable form\n",
    "expected = pd.DataFrame(expected, index=['Female', 'Male'], columns=['Non-Smoker', 'Smoker'])\n",
    "\n",
    "contingency_table.columns = ['Non-Smoker', 'Smoker']\n",
    "contingency_table.index.name = ''\n",
    "\n",
    "contingency_table['group'] = 'Actual'\n",
    "expected['group'] = 'Expected'\n",
    "\n",
    "(pd.concat([contingency_table, expected])\n",
    " .reset_index()\n",
    " .rename({'index': 'sex'}, axis=1)\n",
    " .set_index(['group', 'sex']))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c253e403",
   "metadata": {},
   "source": [
    "Pearson R\n",
    "We can use the pearson r test to compare two continuous variables and see if they are linearly correlated, and the strength of the correlation. We will use the only two continuous variables from our dataset, total_bill and tip. Our null hypothesis for this test is that there is no correlation between the two variables, more formally:\n",
    "\n",
    "H\n",
    "0\n",
    ": There is not linear correlation between the total bill and the tip amount.\n",
    "\n",
    "To perform the test, we can pass the two Series that contain the values we are looking at to the pearsonr function form scipy's stats module.\n",
    "\n",
    "\n",
    "test_results = stats.pearsonr(tips.total_bill, tips.tip)\n",
    "test_results\n",
    "\n",
    "(0.6757341092113641, 6.6924706468642374e-34)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be645b70",
   "metadata": {},
   "source": [
    "This test gives us back two pieces of information:\n",
    "\n",
    "the test statistic, in this case, the r value\n",
    "the p value\n",
    "\n",
    "r, p = test_results\n",
    "\n",
    "print(f'p is {p:.10f}')\n",
    "\n",
    "p is 0.0000000000\n",
    "Since p is 0 within 10 decimal places, we can safely reject the null hypothesis of no linear correlation. Less formally, it seems as though the total bill and tip amount are very related.\n",
    "\n",
    "The test statistic for this test is the r value, which tells us how strongly correlated the two variables are."
   ]
  },
  {
   "cell_type": "raw",
   "id": "532f58ad",
   "metadata": {},
   "source": [
    "# T Test\n",
    "We can use the t-test to compare a categorical feature with a continous feature.\n",
    "\n",
    "We will focus on two kinds of t-tests:\n",
    "\n",
    "1 sample: compares the mean for a subgroup against the population mean\n",
    "2 sample: compares the means for two subgroups\n",
    "In both cases, our null hypothesis is the same: there is no difference in the means.\n",
    "\n",
    "To demonstrate, we'll try to answer two different questions:\n",
    "\n",
    "Is the total bill amount different for smokers?\n",
    "Is the size of the tip different for parties of 2 and parties of 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 Sample T Test\n",
    "Is the total bill amount different for smokers?\n",
    "\n",
    "To answer this question, we need two pieces of information, which we will pass along to scipy:\n",
    "\n",
    "the total bill amounts for all the smokers\n",
    "the overall total bill mean\n",
    "We will feed both of these into the ttest_1samp function from scipy's stats module.\n",
    "\n",
    "Our null hypothesis is that there is no difference, more formally:\n",
    "\n",
    "H\n",
    "0\n",
    ": The average bill for smokers is no different than the population mean."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1684eb68",
   "metadata": {},
   "source": [
    "smokers_total_bills = tips[tips.smoker == 'Yes'].total_bill\n",
    "overall_total_bill_mean = tips.total_bill.mean()\n",
    "\n",
    "test_results = stats.ttest_1samp(smokers_total_bills, overall_total_bill_mean)\n",
    "test_results\n",
    "\n",
    "Ttest_1sampResult(statistic=0.951796790928544, pvalue=0.3436939512284921)\n",
    "This function gives us back two pieces of information, the test statstic and the p-value.\n",
    "\n",
    "In this case, because our p-value is so high, we fail to reject our null hypothesis. Less formally, we conclude that smoker might not have a significant difference in their total bill."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9845fd3e",
   "metadata": {},
   "source": [
    "2 Sample T Test\n",
    "Is the total bill amount different for parties of 2 vs 4?\n",
    "\n",
    "H\n",
    "0\n",
    ": The average size of the tip left by parties of 2 and parties of 4 is the same.\n",
    "\n",
    "For this example, we'll need to create two seperate datasets that contain the values for the continuous variable for each subgroup. In our case, this means we need all the tip values for parties of 2 and the tip values for parties of 4.\n",
    "\n",
    "We'll pass these to the ttest_ind function from scipy's stats module.\n",
    "\n",
    "\n",
    "parties_of_2 = tips[tips['size'] == 2]\n",
    "parties_of_4 = tips[tips['size'] == 4]\n",
    "test_results = stats.ttest_ind(parties_of_2.tip, parties_of_4.tip)\n",
    "test_results\n",
    "\n",
    "Ttest_indResult(statistic=-7.462130391296251, pvalue=2.924028981378475e-12)\n",
    "Like before, the function returns the test statistic and the p-value. Here, with such a small p-value, we reject the null hypothesis. We think there is a significant difference in the average tip amount left by parties of 2 and parties of 4."
   ]
  },
  {
   "cell_type": "raw",
   "id": "20f27498",
   "metadata": {},
   "source": [
    "Summary of Hypothesis Testing and Distributions.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8280863",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
